{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99674450-97a0-485e-a512-7088ab2220d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f3327-b093-4cda-8b13-1df4a14b133d",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are used to describe the probability distribution of a random variable.\n",
    "\n",
    "A Probability Mass Function (PMF) is used for discrete random variables, and it gives the probability of each possible value of the random variable. It is a function that maps each possible value of the random variable to its probability. Mathematically, the PMF is defined as:\n",
    "\n",
    "P(X = x) = p(x)\n",
    "\n",
    "Where X is a discrete random variable, x is a possible value of X, and p(x) is the probability of X taking the value x.\n",
    "\n",
    "For example, consider a fair six-sided die. The random variable X represents the outcome of a single roll of the die. The PMF of X is given by:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "The PMF tells us that the probability of rolling a 1 on the die is 1/6, the probability of rolling a 2 is 1/6, and so on.\n",
    "\n",
    "A Probability Density Function (PDF) is used for continuous random variables, and it gives the probability of a random variable taking on a value within a certain range. It is a function that gives the relative likelihood of different values of the random variable. Mathematically, the PDF is defined as:\n",
    "\n",
    "f(x) = dF(x) / dx\n",
    "\n",
    "Where F(x) is the cumulative distribution function (CDF) of the random variable X, and f(x) is its derivative.\n",
    "\n",
    "For example, consider a normal distribution with mean μ=0 and standard deviation σ=1. The PDF of this distribution is given by:\n",
    "\n",
    "f(x) = (1 / sqrt(2π)) * exp(-(x-μ)^2 / 2σ^2)\n",
    "\n",
    "This function describes the shape of the normal distribution and gives the probability of a value x occurring within a certain range. For instance, the probability of x being within 1 standard deviation of the mean can be calculated by integrating the PDF over that range.\n",
    "\n",
    "The key difference between PMF and PDF is that PMF gives the probability of discrete events while PDF gives the probability density over a continuous range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9433c67-8830-4110-b6a8-b59363633899",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce0447-f761-4ecc-925e-4e616c9f9ac1",
   "metadata": {},
   "source": [
    "Cumulative Density Function (CDF) is a function that gives the probability that a random variable X is less than or equal to a certain value x. It is the integral of the Probability Density Function (PDF) for continuous random variables or the sum of the Probability Mass Function (PMF) for discrete random variables. The CDF is also known as the distribution function.\n",
    "\n",
    "Mathematically, the CDF of a random variable X is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "For example, let's consider a continuous random variable X that follows a normal distribution with mean μ = 2 and standard deviation σ = 1. The PDF of X is given by:\n",
    "\n",
    "f(x) = (1 / sqrt(2πσ^2)) * exp(-(x-μ)^2 / 2σ^2)\n",
    "\n",
    "The CDF of X can be calculated by integrating the PDF from negative infinity to x:\n",
    "\n",
    "F(x) = ∫(-∞,x) f(u) du\n",
    "\n",
    "The resulting function F(x) gives the probability that X is less than or equal to x.\n",
    "\n",
    "The CDF is an important concept in probability theory and statistics because it allows us to calculate probabilities for a wide range of events. For example, we can use the CDF to calculate the probability of a random variable being within a certain range or above a certain threshold. We can also use the CDF to calculate percentiles of a distribution, such as the median or quartiles.\n",
    "\n",
    "In addition, the CDF is useful for comparing different probability distributions and understanding how they relate to each other. For instance, we can compare the CDFs of two different random variables to see which one is more likely to take on a certain value or fall within a certain range.\n",
    "\n",
    "Overall, the CDF is a powerful tool for describing and analyzing the behavior of random variables and is widely used in many fields, including finance, engineering, and the natural sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83737b-a875-4e82-a281-1a34b79cb702",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579d252-7122-4269-9b74-292f4c3f3111",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most commonly used probability distributions in statistics, and it is often used as a model for continuous random variables in a wide range of fields. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights of people in a population\n",
    "Weights of products manufactured by a company\n",
    "IQ scores of a group of people\n",
    "Errors in measurements or observations\n",
    "Stock prices or financial returns\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution and determines the location of the peak. The standard deviation represents the spread or width of the distribution and determines how much the data varies around the mean.\n",
    "\n",
    "The normal distribution is symmetric, with a bell-shaped curve that is highest at the mean and gradually tapers off towards the tails. The exact shape of the distribution depends on the values of μ and σ. A smaller value of σ results in a narrower distribution, while a larger value of σ results in a wider distribution. A positive value of μ shifts the distribution to the right, while a negative value of μ shifts it to the left.\n",
    "\n",
    "The normal distribution is often used as a model because it has several desirable properties, including:\n",
    "\n",
    "It is easy to work with mathematically, making it a convenient tool for modeling and analysis.\n",
    "Many natural phenomena follow a normal distribution, which makes it a useful approximation for many real-world situations.\n",
    "It has well-understood properties, including a fixed mean and standard deviation, and it is easy to calculate probabilities and percentiles based on these parameters.\n",
    "It is a stable distribution, meaning that the sum or average of many independent normal random variables is also normally distributed, making it useful for many statistical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1e6e7-7807-4d23-9143-69a143c91851",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bf6b2-68e2-4cfb-99da-3147dc7bb3a4",
   "metadata": {},
   "source": [
    "The normal distribution is an essential tool in statistics and data analysis due to its numerous applications in a wide range of fields. Some of the important reasons why normal distribution is significant are:\n",
    "\n",
    "It is a widely used probability distribution that approximates the distribution of many real-world phenomena.\n",
    "It is well-understood and easy to work with mathematically, making it a convenient tool for modeling and analysis.\n",
    "Many statistical tests and techniques are based on the assumption of normality, such as hypothesis testing, confidence intervals, and regression analysis.\n",
    "The central limit theorem states that the distribution of the sample mean of a sufficiently large number of independent and identically distributed random variables is approximately normal, regardless of the underlying distribution of the variables. This theorem is crucial for many statistical applications, including quality control, survey sampling, and experimental design.\n",
    "Real-life examples of normal distribution include:\n",
    "\n",
    "Heights and weights of individuals in a population: The distribution of height and weight in a large population tends to follow a normal distribution, with the mean and standard deviation depending on factors such as age, gender, and ethnicity.\n",
    "Test scores: Standardized test scores, such as the SAT or ACT, are often normally distributed. The mean score represents the average performance of all test-takers, while the standard deviation represents how much variation there is in the scores.\n",
    "Errors in measurements: Errors in measurements or observations of physical quantities, such as the length of an object or the temperature of a room, tend to follow a normal distribution. The mean represents the true value of the quantity being measured, while the standard deviation represents the precision of the measurement instrument.\n",
    "Stock prices: Changes in stock prices over time are often normally distributed, with the mean representing the expected return on investment and the standard deviation representing the volatility or risk of the investment.\n",
    "IQ scores: IQ scores of a group of people tend to follow a normal distribution, with the mean set to 100 and the standard deviation set to 15. This distribution allows for the comparison of individual scores to the average performance of the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9a4e6-b07d-4211-acd0-fa30d619cafc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ce6ef-feec-41de-abc5-0d639e928609",
   "metadata": {},
   "source": [
    "Bernoulli distribution is a discrete probability distribution that represents the outcomes of a single binary experiment, where the outcome is either a success or a failure, and the probability of success is denoted by p. It has two possible outcomes: success with probability p and failure with probability 1-p. The Bernoulli distribution is often used in situations where there are only two possible outcomes, and the goal is to understand the probability of one of those outcomes occurring.\n",
    "\n",
    "An example of the Bernoulli distribution is a coin toss. If we assume that the coin is fair, then the probability of getting heads (success) is 0.5, and the probability of getting tails (failure) is also 0.5. Therefore, a coin toss can be modeled using the Bernoulli distribution.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution is used to model the outcome of a single binary experiment, while the binomial distribution is used to model the number of successes in a fixed number of independent Bernoulli trials. In other words, the binomial distribution is the sum of n independent and identically distributed Bernoulli random variables.\n",
    "\n",
    "For example, if we flip a coin 10 times and count the number of heads, the number of heads is a binomial random variable, where each trial is a Bernoulli random variable. The binomial distribution is characterized by two parameters: the number of trials (n) and the probability of success (p) in each trial. In contrast, the Bernoulli distribution has only one parameter, the probability of success (p).\n",
    "\n",
    "Another difference between the two distributions is that the Bernoulli distribution is a special case of the binomial distribution when n=1, which means that the binomial distribution reduces to a Bernoulli distribution when there is only one trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3124b23-a2b5-4205-8d02-5e4d0b07f308",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17503220-7062-452f-be06-246399b8ce79",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation will be greater than 60, we need to use the cumulative distribution function (CDF) of the normal distribution with a mean of 50 and a standard deviation of 10. The CDF gives the probability that a random variable X is less than or equal to a given value x, and is denoted by P(X ≤ x).\n",
    "\n",
    "In this case, we want to find P(X > 60), which is the probability that a randomly selected observation is greater than 60. We can use the fact that P(X > 60) = 1 - P(X ≤ 60), since the total probability is always equal to 1.\n",
    "\n",
    "Using the z-score formula, we can standardize the value 60 to the corresponding z-score:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "We can then use a standard normal distribution table or calculator to find the probability of a z-score being less than or equal to 1, which is 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is:\n",
    "\n",
    "P(X > 60) = 1 - P(X ≤ 60) = 1 - 0.8413 = 0.1587\n",
    "\n",
    "So the probability is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b8668-1633-4fa4-aa21-cf831d89f96c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb0b1b-7b42-4966-b3b9-c95b68ab307d",
   "metadata": {},
   "source": [
    "Uniform distribution is a continuous probability distribution that has a constant probability density function (PDF) between two values, a and b, and zero elsewhere. This means that all values within the range of a and b have an equal chance of occurring.\n",
    "\n",
    "For example, suppose we have a spinner that can land on any number from 1 to 10 with equal probability. The spinner follows a uniform distribution with a = 1 and b = 10, since each number has an equal chance of being landed on. The PDF of the uniform distribution in this case would be a straight line with a constant value of 1/10 between 1 and 10, and zero elsewhere.\n",
    "\n",
    "The probability of the spinner landing on any specific number between 1 and 10 is given by:\n",
    "\n",
    "P(X = x) = 1/10, for x = 1, 2, ..., 10\n",
    "\n",
    "The cumulative distribution function (CDF) of the uniform distribution is a linear function that increases uniformly from 0 to 1 as x increases from a to b. In the case of our spinner, the CDF would be a straight line that starts at 0 when x = 1 and ends at 1 when x = 10.\n",
    "\n",
    "Uniform distribution is commonly used in many applications, such as in random number generation, simulations, and in modeling certain types of phenomena where all values within a certain range have equal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb824f-f3df-41ba-9268-01888d91be1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d4242-ab95-4f4a-9b61-f1c8863116ed",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a dimensionless value that represents the number of standard deviations a data point is away from the mean of a distribution. It is calculated as the difference between the observed value and the mean of the distribution, divided by the standard deviation of the distribution.\n",
    "\n",
    "The formula for the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "x is the observed value\n",
    "μ is the mean of the distribution\n",
    "σ is the standard deviation of the distribution\n",
    "The z-score is important because it allows us to standardize data from different distributions into a common scale, making it easier to compare values across different datasets. It also helps us to identify outliers, as any data point with a z-score greater than 3 (or less than -3) is considered to be an extreme outlier.\n",
    "\n",
    "In addition, the z-score is used in hypothesis testing, where we can compare the z-score of a sample to a standard normal distribution to determine the probability of observing that value by chance alone. This is commonly done using a z-test or a t-test, which are statistical tests that use the z-score to calculate a p-value and assess the statistical significance of the results.\n",
    "\n",
    "Overall, the z-score is a valuable tool in statistics that helps us to understand the relative position of a data point within a distribution and allows us to make comparisons across different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bed749-f4e4-437b-b278-5f3add4c7faf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5cdd8-03ac-4975-b5f2-40c3e867032b",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics. It states that as the sample size increases, the distribution of the sample means approaches a normal distribution, regardless of the shape of the population distribution. More formally, the CLT states that:\n",
    "\n",
    "Given a population with mean μ and standard deviation σ, the sampling distribution of the mean of a random sample of size n will have a mean of μ and a standard deviation of σ/√n.\n",
    "\n",
    "As n increases, the sampling distribution of the mean approaches a normal distribution.\n",
    "\n",
    "The significance of the CLT is that it provides a powerful tool for statistical inference, particularly in situations where the population distribution is not known or is non-normal. By using the CLT, we can make inferences about the population mean based on the sample mean, even if the population distribution is unknown or non-normal.\n",
    "\n",
    "For example, suppose we want to estimate the average height of students in a school, but we do not know the distribution of heights in the population. We can take a random sample of students, calculate their heights, and use the CLT to estimate the mean height of the population. By doing so, we can obtain a good estimate of the population mean even if the population distribution is unknown or non-normal.\n",
    "\n",
    "The CLT also has important practical applications in fields such as finance, quality control, and scientific research. For example, the CLT is used in finance to model the behavior of stock prices and returns, and in quality control to monitor and improve production processes. In scientific research, the CLT is used to estimate the mean and standard deviation of a population based on a sample, as well as to test hypotheses about population parameters. Overall, the CLT is a fundamental concept in statistics that plays a key role in many areas of research and practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a23ff8-49fb-4e3b-9c41-1cdde10f3ac6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb72e0-96de-487b-b487-b0ab9b1cbed2",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is based on a few key assumptions, which are:\n",
    "\n",
    "The sample size is sufficiently large. While there is no strict rule for what constitutes a \"sufficiently large\" sample size, a commonly used guideline is that the sample size should be at least 30.\n",
    "\n",
    "The sample is random. The observations in the sample should be selected independently and at random from the population of interest.\n",
    "\n",
    "The population has a finite mean and finite variance. This assumption is necessary for the standard deviation of the sample mean to be well-defined.\n",
    "\n",
    "The observations in the sample are independent. This assumption means that the value of one observation does not affect the value of another observation in the sample.\n",
    "\n",
    "The sample is drawn from a population that has a fixed distribution. This assumption means that the population distribution does not change over time or between different samples.\n",
    "\n",
    "It is important to note that violating these assumptions can lead to inaccurate or misleading results when using the CLT. For example, if the sample size is too small, the distribution of the sample means may not approximate a normal distribution, even if the population distribution is normal. Similarly, if the observations in the sample are not independent, this can lead to biased estimates of the population mean and standard deviation. Therefore, it is important to carefully consider these assumptions when using the CLT to make statistical inferences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
